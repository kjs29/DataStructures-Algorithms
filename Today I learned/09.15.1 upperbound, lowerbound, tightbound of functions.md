# Asympotic notations

There are different run time functions that can measure the time complexity of algorithms.

## 1 < logn < sqrt(n) < n < nlogn < n<sup>2</sup> < n<sup>3</sup> < 2<sup>n</sup> < 3<sup>n</sup> < n<sup>n</sup>


## Big - O (Big-Oh) notation refers to upperbound

A worst-case time complexity of O(n)

- O(n) (it might have to check every element).

## Big - Ω(omega) notation refers to lowerbound

A best-case time complexity of Ω(1)

- Ω(1) (it might find the element in the first position).

## Θ(theta) notation refers to averagebound

An average time complexity of Θ(n)

- Θ(n) (on average, it checks half the elements).

### Code 

For instance,

Let's say one algorithm's runtime function is `2n+5`.

This algorithm's upperbound (O(n)) is `n`,

lowerbound(Ω(1)) is `O(1)`.

`n`(lowerbound) <= `2n+5` <= `n`(upperbound)

So the tight bound(Θ(n)) is `n`.
